{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预处理得到数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "question_list_path = [f'./question_list/question_list{i}.txt' for i in range(1,5)]\n",
    "feature = []\n",
    "label = []\n",
    "num = 0\n",
    "for question_path in question_list_path :\n",
    "    with open(question_path,'r') as f :\n",
    "        content = f.read().split(\"\\n\")\n",
    "    feature += content\n",
    "    label += [num for i in range(len(content))]\n",
    "    num += 1\n",
    "\n",
    "dataset =pd.DataFrame([feature,label]).transpose()\n",
    "dataset.columns = ['feature','label']\n",
    "dataset.to_excel('./dataset.xlsx',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取预训练大模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda\\envs\\myproject1\\lib\\site-packages\\InstructorEmbedding\\instructor.py:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "function 'cadam32bit_grad_fp32' not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda\\envs\\myproject1\\lib\\site-packages\\bitsandbytes\\cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "from InstructorEmbedding import INSTRUCTOR\n",
    "\n",
    "# 读取本地模型文件\n",
    "model = INSTRUCTOR(\"F:\\\\工作以及比赛\\\\大一统框架\\\\dd\\\\try2\\\\t1\\\\model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将语料库中的语句转化为句向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# 读取数据\n",
    "dataset = pd.read_excel('./dataset.xlsx')\n",
    "# 转化为句向量\n",
    "dataset = np.concatenate([model.encode(dataset['feature'].to_numpy()),torch.nn.functional.one_hot(torch.tensor(dataset['label'].to_numpy()),num_classes=4)],axis=1)\n",
    "# 划分训练集和测试集\n",
    "traindataset,testdataset = train_test_split(dataset,test_size=0.3,shuffle=True)\n",
    "# 划分特征空间和标签\n",
    "feature_train,label_train = traindataset[:,0:-4],traindataset[:,traindataset.shape[-1]-4:traindataset.shape[-1]]\n",
    "feature_test,label_test = testdataset[:,0:-4],testdataset[:,testdataset.shape[-1]-4:testdataset.shape[-1]]\n",
    "# 转换为torch风格的dataset\n",
    "traindataset = torch.utils.data.TensorDataset(torch.Tensor(feature_train),torch.Tensor(label_train))\n",
    "testdataset = torch.utils.data.TensorDataset(torch.Tensor(feature_test),torch.Tensor(label_test))\n",
    "# 定义批处理器\n",
    "# batch_size = 10 \n",
    "# traindataloader = torch.utils.data.DataLoader(traindataset,batch_size=batch_size,drop_last=True)\n",
    "# testdataloader = torch.utils.data.DataLoader(testdataset,batch_size=batch_size,drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 准备训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def score_func(batch_size,hidden_size,drop_prod,num_layers,activate_func,lr,epochs) :\n",
    "    # 预处理bayes优化传的参数\n",
    "    batch_size = int(batch_size)\n",
    "    hidden_size = int(hidden_size)\n",
    "    epochs = int(epochs)\n",
    "    num_layers = int(num_layers)\n",
    "    activate_func = ['relu','sigmoid','tanh'][int(activate_func)]\n",
    "    \n",
    "    # 定义批处理器\n",
    "    traindataloader = torch.utils.data.DataLoader(traindataset,batch_size=batch_size,drop_last=True)\n",
    "    testdataloader = torch.utils.data.DataLoader(testdataset,batch_size=batch_size,drop_last=True)\n",
    "\n",
    "    # 定义神经网络结构\n",
    "    class network(nn.Module) :\n",
    "        def __init__(self,input_size,hidden_size,drop_prod,num_layers,activate_func) :\n",
    "            super().__init__()\n",
    "            # 激活函数可供选择\n",
    "            if activate_func == 'relu' :\n",
    "                acf = nn.ReLU()\n",
    "            elif activate_func == 'sigmoid' :\n",
    "                acf = nn.Sigmoid()\n",
    "            elif activate_func == 'tanh' :\n",
    "                acf = nn.Tanh()\n",
    "            \n",
    "            layer_list = [\n",
    "                nn.Linear(in_features = input_size,out_features = hidden_size,bias = True),\n",
    "                acf,\n",
    "                nn.Dropout(p=drop_prod),\n",
    "            ]\n",
    "\n",
    "            for i in range(num_layers-1) :\n",
    "                layer_list.append(nn.Linear(in_features = hidden_size,out_features = hidden_size,bias = True))\n",
    "                layer_list.append(acf)\n",
    "                layer_list.append(nn.Dropout(p=drop_prod))\n",
    "            \n",
    "            layer_list.append(nn.Linear(in_features = hidden_size,out_features = 4 ,bias = True))\n",
    "            self.model = nn.Sequential(*layer_list)\n",
    "\n",
    "        def forward(self,x) :\n",
    "            return self.model(x)\n",
    "\n",
    "    # 实例化网络\n",
    "    input_size = dataset.shape[-1] - 4\n",
    "    # hidden_size = 256\n",
    "    # drop_prod = 0.8\n",
    "    net = network(input_size=input_size,hidden_size=hidden_size,drop_prod=drop_prod,num_layers=num_layers,activate_func=activate_func)\n",
    "\n",
    "    # 迁移模型\n",
    "    # net.to(\"cuda:0\")\n",
    "\n",
    "    # 定义优化器\n",
    "    # lr = 1e-3\n",
    "    optimizer =torch.optim.Adam(net.parameters(),lr)\n",
    "\n",
    "    # 定义损失函数\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    # 初始化参数\n",
    "    for name,param in net.named_parameters() :\n",
    "        if \"bias\" in name :\n",
    "            nn.init.constant_(param,val=0)\n",
    "        elif \"weight\" in name :\n",
    "            nn.init.normal_(param,mean=0,std=1)\n",
    "\n",
    "    # epochs = 3000\n",
    "    for epoch in range(epochs) :\n",
    "        ls = 0\n",
    "        # 开启训练模式\n",
    "        net.train()\n",
    "        for pi_X,pi_y in traindataloader :\n",
    "            # 迁移数据\n",
    "            # pi_X = pi_X.to(\"cuda:0\")\n",
    "            # pi_y = pi_y.to(\"cuda:0\")\n",
    "            l = loss(net(pi_X),pi_y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            ls += l\n",
    "        lt = 0\n",
    "        a = 0\n",
    "        t = 0\n",
    "        with torch.no_grad():\n",
    "            # 开启评估模式\n",
    "            net.eval()\n",
    "            for pi_X_test,pi_y_test in testdataloader :\n",
    "                # pi_X_test = pi_X_test.to(\"cuda:0\")\n",
    "                # pi_y_test = pi_y_test.to(\"cuda:0\")\n",
    "                lt += loss(net(pi_X_test),pi_y_test)\n",
    "                a += ((net(pi_X_test).argmax(dim=1) == pi_y_test.argmax(dim=1))).sum()\n",
    "                t += pi_X_test.shape[0]\n",
    "            ac = a / t\n",
    "            # print(ls,lt,a)\n",
    "\n",
    "    return ac , net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_bayes = (5,100)\n",
    "hidden_size_bayes = (100,400)\n",
    "drop_prod_bayes = (0.2,0.8)\n",
    "num_layers_bayes = (1,5)\n",
    "activate_func_bayes = (0,2)\n",
    "lr_bayes = (1e-3,5e-2)\n",
    "epochs_bayes = (1000,3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "score_func_score = lambda **kwargs : score_func(**kwargs)[0]\n",
    "\n",
    "param_dict = {\n",
    "    \"batch_size\":batch_size_bayes,\n",
    "    \"hidden_size\":hidden_size_bayes,\n",
    "    \"drop_prod\":drop_prod_bayes,\n",
    "    \"num_layers\":num_layers_bayes,\n",
    "    \"activate_func\":activate_func_bayes,\n",
    "    \"lr\":lr_bayes,\n",
    "    \"epochs\":epochs_bayes,\n",
    "}\n",
    "opt = BayesianOptimization(score_func_score,param_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | activa... | batch_... | drop_prod |  epochs   | hidden... |    lr     | num_la... |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.2128   \u001b[0m | \u001b[0m0.07772  \u001b[0m | \u001b[0m47.63    \u001b[0m | \u001b[0m0.6244   \u001b[0m | \u001b[0m2.744e+03\u001b[0m | \u001b[0m161.5    \u001b[0m | \u001b[0m0.04823  \u001b[0m | \u001b[0m4.549    \u001b[0m |\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m0.2581   \u001b[0m | \u001b[95m0.1231   \u001b[0m | \u001b[95m31.73    \u001b[0m | \u001b[95m0.3555   \u001b[0m | \u001b[95m1.575e+03\u001b[0m | \u001b[95m170.7    \u001b[0m | \u001b[95m0.03088  \u001b[0m | \u001b[95m4.635    \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m0.2525   \u001b[0m | \u001b[0m1.315    \u001b[0m | \u001b[0m33.03    \u001b[0m | \u001b[0m0.4891   \u001b[0m | \u001b[0m1.603e+03\u001b[0m | \u001b[0m309.2    \u001b[0m | \u001b[0m0.009012 \u001b[0m | \u001b[0m3.381    \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.23     \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m100.0    \u001b[0m | \u001b[0m0.8      \u001b[0m | \u001b[0m1e+03    \u001b[0m | \u001b[0m100.0    \u001b[0m | \u001b[0m0.00973  \u001b[0m | \u001b[0m5.0      \u001b[0m |\n",
      "| \u001b[95m5        \u001b[0m | \u001b[95m0.2685   \u001b[0m | \u001b[95m0.08511  \u001b[0m | \u001b[95m27.04    \u001b[0m | \u001b[95m0.5955   \u001b[0m | \u001b[95m1.57e+03 \u001b[0m | \u001b[95m182.8    \u001b[0m | \u001b[95m0.00428  \u001b[0m | \u001b[95m2.206    \u001b[0m |\n",
      "| \u001b[95m6        \u001b[0m | \u001b[95m0.27     \u001b[0m | \u001b[95m0.5922   \u001b[0m | \u001b[95m25.68    \u001b[0m | \u001b[95m0.5915   \u001b[0m | \u001b[95m1.568e+03\u001b[0m | \u001b[95m188.7    \u001b[0m | \u001b[95m0.04698  \u001b[0m | \u001b[95m4.631    \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.2368   \u001b[0m | \u001b[0m0.81     \u001b[0m | \u001b[0m19.7     \u001b[0m | \u001b[0m0.4831   \u001b[0m | \u001b[0m1.502e+03\u001b[0m | \u001b[0m195.8    \u001b[0m | \u001b[0m0.04332  \u001b[0m | \u001b[0m1.203    \u001b[0m |\n",
      "| \u001b[95m8        \u001b[0m | \u001b[95m0.56     \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m50.32    \u001b[0m | \u001b[95m0.8      \u001b[0m | \u001b[95m1.589e+03\u001b[0m | \u001b[95m227.4    \u001b[0m | \u001b[95m0.001    \u001b[0m | \u001b[95m1.0      \u001b[0m |\n",
      "| \u001b[95m9        \u001b[0m | \u001b[95m0.6029   \u001b[0m | \u001b[95m1.043    \u001b[0m | \u001b[95m68.59    \u001b[0m | \u001b[95m0.3452   \u001b[0m | \u001b[95m1.601e+03\u001b[0m | \u001b[95m230.7    \u001b[0m | \u001b[95m0.005701 \u001b[0m | \u001b[95m1.707    \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.2577   \u001b[0m | \u001b[0m1.336    \u001b[0m | \u001b[0m97.31    \u001b[0m | \u001b[0m0.7989   \u001b[0m | \u001b[0m1.573e+03\u001b[0m | \u001b[0m230.4    \u001b[0m | \u001b[0m0.02384  \u001b[0m | \u001b[0m4.853    \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m0.25     \u001b[0m | \u001b[0m1.605    \u001b[0m | \u001b[0m54.37    \u001b[0m | \u001b[0m0.5048   \u001b[0m | \u001b[0m1.621e+03\u001b[0m | \u001b[0m222.2    \u001b[0m | \u001b[0m0.02242  \u001b[0m | \u001b[0m3.847    \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m0.4492   \u001b[0m | \u001b[0m0.7179   \u001b[0m | \u001b[0m59.52    \u001b[0m | \u001b[0m0.2447   \u001b[0m | \u001b[0m1.583e+03\u001b[0m | \u001b[0m220.6    \u001b[0m | \u001b[0m0.04659  \u001b[0m | \u001b[0m1.974    \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m0.2619   \u001b[0m | \u001b[0m1.135    \u001b[0m | \u001b[0m42.61    \u001b[0m | \u001b[0m0.7507   \u001b[0m | \u001b[0m1.591e+03\u001b[0m | \u001b[0m225.0    \u001b[0m | \u001b[0m0.03763  \u001b[0m | \u001b[0m4.552    \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m0.2627   \u001b[0m | \u001b[0m0.1127   \u001b[0m | \u001b[0m59.26    \u001b[0m | \u001b[0m0.38     \u001b[0m | \u001b[0m1.58e+03 \u001b[0m | \u001b[0m212.7    \u001b[0m | \u001b[0m0.03373  \u001b[0m | \u001b[0m4.328    \u001b[0m |\n",
      "| \u001b[95m15       \u001b[0m | \u001b[95m0.6094   \u001b[0m | \u001b[95m1.515    \u001b[0m | \u001b[95m64.02    \u001b[0m | \u001b[95m0.2121   \u001b[0m | \u001b[95m1.602e+03\u001b[0m | \u001b[95m229.9    \u001b[0m | \u001b[95m0.01828  \u001b[0m | \u001b[95m1.955    \u001b[0m |\n",
      "| \u001b[95m16       \u001b[0m | \u001b[95m0.6167   \u001b[0m | \u001b[95m0.0      \u001b[0m | \u001b[95m60.71    \u001b[0m | \u001b[95m0.8      \u001b[0m | \u001b[95m1.592e+03\u001b[0m | \u001b[95m233.3    \u001b[0m | \u001b[95m0.001    \u001b[0m | \u001b[95m1.0      \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m0.2315   \u001b[0m | \u001b[0m1.61     \u001b[0m | \u001b[0m54.37    \u001b[0m | \u001b[0m0.4829   \u001b[0m | \u001b[0m1.587e+03\u001b[0m | \u001b[0m253.6    \u001b[0m | \u001b[0m0.01322  \u001b[0m | \u001b[0m4.432    \u001b[0m |\n",
      "| \u001b[95m18       \u001b[0m | \u001b[95m0.6271   \u001b[0m | \u001b[95m0.3706   \u001b[0m | \u001b[95m59.78    \u001b[0m | \u001b[95m0.3226   \u001b[0m | \u001b[95m1.605e+03\u001b[0m | \u001b[95m244.2    \u001b[0m | \u001b[95m0.01089  \u001b[0m | \u001b[95m1.71     \u001b[0m |\n",
      "=============================================================================================================\n",
      "{'target': 0.6271186470985413, 'params': {'activate_func': 0.3705681065462436, 'batch_size': 59.77729603397106, 'drop_prod': 0.32255092815907316, 'epochs': 1604.663743917312, 'hidden_size': 244.2402375610829, 'lr': 0.01088685506276649, 'num_layers': 1.7098777476474254}}\n"
     ]
    }
   ],
   "source": [
    "opt.maximize(n_iter=15, init_points=3)\n",
    "print(opt.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_func_model = lambda **kwargs : score_func(**kwargs)[-1]\n",
    "\n",
    "mynet = score_func_model(**opt.max['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "network(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=244, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.32255092815907316, inplace=False)\n",
       "    (3): Linear(in_features=244, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mynet.eval()\n",
    "\n",
    "# mynet(torch.Tensor(feature_test))\n",
    "mynet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5833)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(mynet(torch.Tensor(feature_test)).argmax(dim=1) == torch.Tensor(label_test).argmax(dim=1)) / label_test.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 1, 3, 1, 3, 1, 2, 0, 0, 3, 0, 2, 0, 2, 3, 1, 3, 0, 0, 3, 2, 0, 0,\n",
       "        2, 1, 1, 3, 2, 2, 2, 0, 2, 2, 0, 2, 0, 2, 2, 2, 2, 1, 2, 3, 3, 1, 3, 2,\n",
       "        2, 1, 3, 1, 0, 3, 0, 3, 3, 0, 2, 3, 2, 0, 3, 2, 3, 0, 1, 2, 2, 3, 3, 3,\n",
       "        2, 3, 0, 3, 3, 3, 0, 2, 2, 3, 0, 3, 1, 0, 1, 0, 3, 2, 1, 3, 3, 2, 3, 2,\n",
       "        2, 1, 2, 3, 1, 3, 0, 2, 1, 1, 0, 1, 3, 1, 1, 1, 2, 1, 1, 2, 2, 3, 1, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mynet(torch.Tensor(feature_test)).argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "network(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=244, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.32255092815907316, inplace=False)\n",
       "    (3): Linear(in_features=244, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "# 保存模型参数\n",
    "torch.save(mynet.state_dict(),\"./model_params.pth\")\n",
    "\n",
    "# 保存网络结构参数\n",
    "with open(\"./model_struct.json\",\"w\",encoding = \"utf8\") as f :\n",
    "    f.write(json.dumps(opt.max[\"params\"]))\n",
    "\n",
    "# 加载网络结构参数\n",
    "with open(\"./model_struct.json\",\"r\") as f :\n",
    "    content = f.read()\n",
    "model_struct = json.loads(content)\n",
    "\n",
    "# 定义网络结构\n",
    "class network(nn.Module) :\n",
    "    def __init__(self,input_size,hidden_size,drop_prod,num_layers,activate_func) :\n",
    "        super().__init__()\n",
    "        # 激活函数可供选择\n",
    "        if activate_func == 'relu' :\n",
    "            acf = nn.ReLU()\n",
    "        elif activate_func == 'sigmoid' :\n",
    "            acf = nn.Sigmoid()\n",
    "        elif activate_func == 'tanh' :\n",
    "            acf = nn.Tanh()\n",
    "        \n",
    "        layer_list = [\n",
    "            nn.Linear(in_features = input_size,out_features = hidden_size,bias = True),\n",
    "            acf,\n",
    "            nn.Dropout(p=drop_prod),\n",
    "        ]\n",
    "\n",
    "        for i in range(num_layers-1) :\n",
    "            layer_list.append(nn.Linear(in_features = hidden_size,out_features = hidden_size,bias = True))\n",
    "            layer_list.append(acf)\n",
    "            layer_list.append(nn.Dropout(p=drop_prod))\n",
    "        \n",
    "        layer_list.append(nn.Linear(in_features = hidden_size,out_features = 4 ,bias = True))\n",
    "        self.model = nn.Sequential(*layer_list)\n",
    "\n",
    "    def forward(self,x) :\n",
    "        return self.model(x)\n",
    "\n",
    "# 定义网络结构参数\n",
    "hidden_size = model_struct[\"hidden_size\"]\n",
    "drop_prod = model_struct[\"drop_prod\"]\n",
    "num_layers = model_struct[\"num_layers\"]\n",
    "activate_func = model_struct[\"activate_func\"]\n",
    "\n",
    "# 定义模型\n",
    "model_ll = network(input_size=768,hidden_size=int(hidden_size),drop_prod=drop_prod,num_layers=int(num_layers),activate_func=[\"relu\",\"sigmoid\",\"tanh\"][int(activate_func)])\n",
    "\n",
    "# 加载模型参数\n",
    "model_ll.load_state_dict(torch.load(\"./model_params.pth\"))\n",
    "model_ll.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5833)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(model_ll(torch.Tensor(feature_test)).argmax(dim=1) == torch.Tensor(label_test).argmax(dim=1)) / label_test.__len__()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myproject1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
